{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e613ae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hienle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hienle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/hienle/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1049bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "with open('review_training.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "# Extract text and labels\n",
    "train_data = {'label': [], 'review': []}\n",
    "for line in lines:\n",
    "    parts = line.split(': ', 1)\n",
    "    if len(parts) == 2:\n",
    "        label, review = parts\n",
    "        train_data['review'].append(review.strip())\n",
    "        train_data['label'].append(label.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bc5c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for training\n",
    "df_train = pd.DataFrame(train_data)\n",
    "\n",
    "# Preprocess the training data\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "557c0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_train['cleaned_text'] = df_train['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64f451e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     really loved time amount research volunteers h...\n",
      "1     campus huge beautiful need work professors man...\n",
      "2     good place get degree social life meh food bad...\n",
      "3     currently year york found complaints york true...\n",
      "4     york horrible university gone strike many time...\n",
      "5     overall okay school safety remains concern man...\n",
      "6     found york terrible school learning really lik...\n",
      "7     make many people like commute really show clas...\n",
      "8                      school safe school always strike\n",
      "9        school good nothing incredible bad love campus\n",
      "10    value self human please stay away years life w...\n",
      "11    good school learning reputation sucks social l...\n",
      "12    york university toronto faculties offering div...\n",
      "13    york popular law business liberal arts fine ar...\n",
      "14    honestly great time encounter good bad situati...\n",
      "15    going cuz close home program good profs usuall...\n",
      "16    york horrible university gone strike many time...\n",
      "17    good overall ultimately make location bit jank...\n",
      "18    keep school hard make friends safe least since...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "615ee4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing data\n",
    "with open('review_testing.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract text and labels\n",
    "test_data = {'label': [], 'review': []}\n",
    "for line in lines:\n",
    "    parts = line.split(': ', 1)\n",
    "    if len(parts) == 2:\n",
    "        label, review = parts\n",
    "        test_data['review'].append(review.strip())\n",
    "        test_data['label'].append(label.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "366560b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for testing\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "# Preprocess the testing data\n",
    "df_test['cleaned_text'] = df_test['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c489a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bag-of-Words model\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['cleaned_text'])\n",
    "X_test = vectorizer.transform(df_test['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1881b375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc5e1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01e7454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 22.22%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.18      1.00      0.30         3\n",
      "     neutral       1.00      0.14      0.25         7\n",
      "    positive       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.39      0.38      0.18        18\n",
      "weighted avg       0.42      0.22      0.15        18\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0]\n",
      " [6 1 0]\n",
      " [8 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hienle/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hienle/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hienle/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(df_test['label'], predictions)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(df_test['label'], predictions))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(df_test['label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f157d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned Text True Label  \\\n",
      "0   safety isnt always amazing expect school heart...   positive   \n",
      "1   tmu good diverse school heart toronto incredib...    neutral   \n",
      "2   overall great school heart toronto lots opport...    neutral   \n",
      "3   want tools change world equitable improve huma...   positive   \n",
      "4   student location convenient unfortunately hear...   positive   \n",
      "5   good vibes competitive needs residence space c...    neutral   \n",
      "6   overall would give university solid good diver...   positive   \n",
      "7   pros offers lots online courses close subway c...    neutral   \n",
      "8   location university inviting homeless populati...   negative   \n",
      "9   university regard students professors lecture ...   negative   \n",
      "10  solid first year staying dcc lots areas chill ...    neutral   \n",
      "11  location pretty great ttc mall restaurants clo...    neutral   \n",
      "12  overall great school positive atmosphere vibin...   positive   \n",
      "13  social skills fit right place meet people expe...   negative   \n",
      "14  commuter school hard decent social life unless...    neutral   \n",
      "15  love location makes feel much uplifting hardly...   positive   \n",
      "16  heart downtown want food eaton centre minute w...   positive   \n",
      "17  awesome school great location youre gta best o...   positive   \n",
      "\n",
      "   Predicted Label  \n",
      "0         negative  \n",
      "1         negative  \n",
      "2         negative  \n",
      "3         negative  \n",
      "4         negative  \n",
      "5         negative  \n",
      "6         negative  \n",
      "7         negative  \n",
      "8         negative  \n",
      "9         negative  \n",
      "10        negative  \n",
      "11         neutral  \n",
      "12        negative  \n",
      "13        negative  \n",
      "14        negative  \n",
      "15        negative  \n",
      "16        negative  \n",
      "17        negative  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "result_df = pd.DataFrame({\n",
    "    'Cleaned Text': df_test['cleaned_text'],\n",
    "    'True Label': df_test['label'],\n",
    "    'Predicted Label': predictions,\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f41d08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply SentimentIntensityAnalyzer to obtain compound scores\n",
    "df_test['compound'] = df_test['cleaned_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Convert compound scores to predicted labels\n",
    "df_test['predicted_label'] = df_test['compound'].apply(lambda score: 'positive' if score >= 0 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4678952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned Text True Label  \\\n",
      "0   safety isnt always amazing expect school heart...   positive   \n",
      "1   tmu good diverse school heart toronto incredib...    neutral   \n",
      "2   overall great school heart toronto lots opport...    neutral   \n",
      "3   want tools change world equitable improve huma...   positive   \n",
      "4   student location convenient unfortunately hear...   positive   \n",
      "5   good vibes competitive needs residence space c...    neutral   \n",
      "6   overall would give university solid good diver...   positive   \n",
      "7   pros offers lots online courses close subway c...    neutral   \n",
      "8   location university inviting homeless populati...   negative   \n",
      "9   university regard students professors lecture ...   negative   \n",
      "10  solid first year staying dcc lots areas chill ...    neutral   \n",
      "11  location pretty great ttc mall restaurants clo...    neutral   \n",
      "12  overall great school positive atmosphere vibin...   positive   \n",
      "13  social skills fit right place meet people expe...   negative   \n",
      "14  commuter school hard decent social life unless...    neutral   \n",
      "15  love location makes feel much uplifting hardly...   positive   \n",
      "16  heart downtown want food eaton centre minute w...   positive   \n",
      "17  awesome school great location youre gta best o...   positive   \n",
      "\n",
      "   Predicted Label  \n",
      "0         positive  \n",
      "1         positive  \n",
      "2         positive  \n",
      "3         positive  \n",
      "4         positive  \n",
      "5         positive  \n",
      "6         positive  \n",
      "7         negative  \n",
      "8         positive  \n",
      "9         positive  \n",
      "10        positive  \n",
      "11        positive  \n",
      "12        positive  \n",
      "13        positive  \n",
      "14        positive  \n",
      "15        negative  \n",
      "16        positive  \n",
      "17        positive  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "result_df = pd.DataFrame({\n",
    "    'Cleaned Text': df_test['cleaned_text'],\n",
    "    'True Label': df_test['label'],\n",
    "    'Predicted Label': df_test['predicted_label'],\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c14a9c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 38.89%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.44      0.88      0.58         8\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.15      0.29      0.19        18\n",
      "weighted avg       0.19      0.39      0.26        18\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 3]\n",
      " [1 0 6]\n",
      " [1 0 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hienle/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hienle/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hienle/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(df_test['label'], df_test['predicted_label'])\n",
    "print(f'\\nAccuracy: {accuracy:.2%}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(df_test['label'], df_test['predicted_label']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(df_test['label'], df_test['predicted_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffef7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply SentimentIntensityAnalyzer to obtain compound scores\n",
    "df_test['compound'] = df_test['cleaned_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Adjust the threshold for considering a text as neutral\n",
    "neutral_threshold = 0.5\n",
    "df_test['predicted_label'] = df_test['compound'].apply(lambda score: 'positive' if score > neutral_threshold else 'negative' if score < -neutral_threshold else 'neutral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20a3f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned Text True Label  \\\n",
      "0   safety isnt always amazing expect school heart...   positive   \n",
      "1   tmu good diverse school heart toronto incredib...    neutral   \n",
      "2   overall great school heart toronto lots opport...    neutral   \n",
      "3   want tools change world equitable improve huma...   positive   \n",
      "4   student location convenient unfortunately hear...   positive   \n",
      "5   good vibes competitive needs residence space c...    neutral   \n",
      "6   overall would give university solid good diver...   positive   \n",
      "7   pros offers lots online courses close subway c...    neutral   \n",
      "8   location university inviting homeless populati...   negative   \n",
      "9   university regard students professors lecture ...   negative   \n",
      "10  solid first year staying dcc lots areas chill ...    neutral   \n",
      "11  location pretty great ttc mall restaurants clo...    neutral   \n",
      "12  overall great school positive atmosphere vibin...   positive   \n",
      "13  social skills fit right place meet people expe...   negative   \n",
      "14  commuter school hard decent social life unless...    neutral   \n",
      "15  love location makes feel much uplifting hardly...   positive   \n",
      "16  heart downtown want food eaton centre minute w...   positive   \n",
      "17  awesome school great location youre gta best o...   positive   \n",
      "\n",
      "   Predicted Label  Compound Score  \n",
      "0         positive          0.7023  \n",
      "1         positive          0.6597  \n",
      "2         positive          0.9382  \n",
      "3         positive          0.7269  \n",
      "4         positive          0.7003  \n",
      "5         positive          0.7269  \n",
      "6         positive          0.8807  \n",
      "7         negative         -0.6007  \n",
      "8         positive          0.8225  \n",
      "9          neutral          0.0000  \n",
      "10        positive          0.8934  \n",
      "11        positive          0.7783  \n",
      "12        positive          0.8271  \n",
      "13        positive          0.8225  \n",
      "14        positive          0.8591  \n",
      "15        negative         -0.6549  \n",
      "16        positive          0.9319  \n",
      "17        positive          0.9246  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "result_df = pd.DataFrame({\n",
    "    'Cleaned Text': df_test['cleaned_text'],\n",
    "    'True Label': df_test['label'],\n",
    "    'Predicted Label': df_test['predicted_label'],\n",
    "    'Compound Score': df_test['compound'],\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4c1c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 38.89%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "     neutral       0.00      0.00      0.00         7\n",
      "    positive       0.47      0.88      0.61         8\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.16      0.29      0.20        18\n",
      "weighted avg       0.21      0.39      0.27        18\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 2]\n",
      " [1 0 6]\n",
      " [1 0 7]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(df_test['label'], df_test['predicted_label'])\n",
    "print(f'\\nAccuracy: {accuracy:.2%}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(df_test['label'], df_test['predicted_label']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(df_test['label'], df_test['predicted_label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
